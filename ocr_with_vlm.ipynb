{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc2f38ef",
   "metadata": {},
   "source": [
    "## **Import necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fbee9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/syahputra/miniconda3/envs/lmstudio/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook\n",
    "from evaluate import load\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import lmstudio as lms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1c404",
   "metadata": {},
   "source": [
    "## **Define paths to dataset and output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bba30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"dataset/images\"\n",
    "gt_folder = \"dataset/ground-truth\"\n",
    "output_excel = \"result/prediction.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39059c",
   "metadata": {},
   "source": [
    "## **Model initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb685a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lms.llm(\"google/gemma-3-4b\")\n",
    "# model = lms.llm(\"google/gemma-3-12b:gemma-3-12b-it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b80bfa6",
   "metadata": {},
   "source": [
    "## **Excel file setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5956d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"plate number predictions\"\n",
    "ws.append([\"image\", \"ground_truth\", \"prediction\", \"CER_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d61cad9",
   "metadata": {},
   "source": [
    "## **Define CER score calculation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e860d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(predictions, ground_truths):\n",
    "    cer_metric = load(\"cer\")\n",
    "    result = cer_metric.compute(predictions=predictions, references=ground_truths)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea222630",
   "metadata": {},
   "source": [
    "## **List all image files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "097bac71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images found: 20\n"
     ]
    }
   ],
   "source": [
    "ekstensi_gambar = [\".jpg\", \".jpeg\", \".png\"]\n",
    "files = os.listdir(image_folder)\n",
    "gambar_files = [f for f in files if os.path.splitext(f)[1].lower() in ekstensi_gambar]\n",
    "gambar_files.sort()\n",
    "\n",
    "print(f\"Images found: {len(gambar_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75eac17",
   "metadata": {},
   "source": [
    "## **Main prediction loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c52233e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample1.jpg → GT: N1365AA0, Pred: N1365AA0, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample10.jpg → GT: L7540GP, Pred: L7540GP, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample11.jpg → GT: N1112BU, Pred: 1112BU, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample12.jpg → GT: L1707WE, Pred: 1707WE, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample13.jpg → GT: L1792AAQ, Pred: L1792AAQ, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample14.jpg → GT: L1952VG, Pred: 1952VG, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample15.jpg → GT: L1213HX, Pred: 1213HX, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample16.jpg → GT: L1983ZP, Pred: 1983ZP, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample17.jpg → GT: L1549AB0, Pred: L1549AB0, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample18.jpg → GT: L1952VG, Pred: 1952VG, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample19.jpg → GT: W1714W0, Pred: W1714W0, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample2.jpg → GT: N1077AAK, Pred: N1077AAK, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample20.jpg → GT: H9417OR, Pred: H9417OR, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample3.jpg → GT: N1084AA0, Pred: N1084AA0, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample4.jpg → GT: N1610KS, Pred: 1610KS, CER: 0.143\n",
      "--------------------------------------------------------------------------------\n",
      "sample5.jpg → GT: N924CIA, Pred: N924CIA, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample6.jpg → GT: B1995SMJ, Pred: B1995SMJ, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample7.jpg → GT: B1813VMF, Pred: 1813VMF, CER: 0.125\n",
      "--------------------------------------------------------------------------------\n",
      "sample8.jpg → GT: B2006KZH, Pred: B2006KZH, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n",
      "sample9.jpg → GT: L1778CP, Pred: L1778CP, CER: 0.000\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for gambar in gambar_files:\n",
    "    nama = os.path.splitext(gambar)[0]\n",
    "    image_path = os.path.join(image_folder, gambar)\n",
    "    txt_path = os.path.join(gt_folder, f\"{nama}.txt\")\n",
    "\n",
    "    if not os.path.exists(txt_path):\n",
    "        print(f\"Cannot find ground truth for {gambar}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        ground_truth = f.read().strip()\n",
    "\n",
    "    image_handle = lms.prepare_image(image_path)\n",
    "\n",
    "    chat = lms.Chat()\n",
    "    chat.add_user_message(\n",
    "        \"What is the license plate number shown in this image? Respond only with the license plate characters, without any spaces, or punctuation. Do not include the expiration date.\",\n",
    "        images=[image_handle]\n",
    "    )\n",
    "\n",
    "    prediction_result = model.respond(chat)\n",
    "    prediction = prediction_result.content.strip()\n",
    "    cer_score = calculate_cer([prediction], [ground_truth])\n",
    "\n",
    "    ws.append([gambar, ground_truth, prediction, round(cer_score, 3)])\n",
    "    results.append([gambar, ground_truth, prediction, round(cer_score, 3)])\n",
    "    print(f\"{gambar} → GT: {ground_truth}, Pred: {prediction}, CER: {cer_score:.3f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33321b19",
   "metadata": {},
   "source": [
    "## **Save excel file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be30129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: result/prediction.xlsx\n"
     ]
    }
   ],
   "source": [
    "wb.save(output_excel)\n",
    "print(f\"Results saved to: {output_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78bfd33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: result/prediction.csv\n"
     ]
    }
   ],
   "source": [
    "output_csv = \"result/prediction.csv\"\n",
    "os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "\n",
    "with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"image\", \"ground_truth\", \"prediction\", \"CER_score\"])\n",
    "    writer.writerows(results)\n",
    "\n",
    "print(f\"Results saved to: {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmstudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
